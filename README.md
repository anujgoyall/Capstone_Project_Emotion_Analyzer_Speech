# Capstone_Project_Emotion_Analyzer_Speech
Speech is recognized as the most natural way of self-expression for humans. It is essential to our rational as well as smart decisions. Speech Emotion Recognition (SER) can be defined as extraction of the emotional aspects of the speaker from his or her speech signal irrespective of its semantic content. It is a collection of methodologies to process and classify speech signals to detect the embedded emotions.
However, emotions are subjective to numerous interpretations making it hard to underline the notion behind the emotions. It is hard to annotate an audio recording. Should we label a single word, sentence or a whole conversation? How many emotions should we define to recognize? Data selection is hard - to find un-adulterated audio recordings is a challenge.
Project is targeted to explore how to use machine learning to detect human emotions from audio recordings and its potential in real world scenarios. There are several applications for detecting human emotion interface with robots, audio surveillance, web-based E-learning, commercial apps, medical studies, entertainment, banking, call centers, pilots, computer games, etc. For online classrooms, information about the emotional state of students can help in improvement in teaching techniques. For example, a teacher can use SER to decide what subjects can be taught and must be able to develop strategies for managing emotions within the learning.
This project is an attempt to build, train, and test a convolutional neural network to classify underlying emotions in recorded audio files by analysing the acoustic features in it.
