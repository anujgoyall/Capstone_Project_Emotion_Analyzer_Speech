# -*- coding: utf-8 -*-
"""Feature_extraction,Model_building_&_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/anujgoyall/Speech-Emotion-Recognition-/blob/main/Feature_extraction%2CModel_building_%26_Prediction_Final%20.ipynb
"""

#Speech Emotion Analyzer using Convolutional Neural Network
#Importing Libraries
import os # provides functions for interacting with the operating
import sys # provides information about constants, functions and methods
import glob # glob module is used to retrieve files/pathnames matching a specified pattern
import numpy as np # used for working with arrays
import pandas as pd # library used for data analysis 

'''Import audio files
pip install librosa. Run this command in terminal to install librosa library'''

import librosa # librosa is a package to use audio files
import librosa.display  # for usage with audio signals
from scipy.io import wavfile #to import wav file
import scipy.io.wavfile
#import sys
import numpy as nm
''' Importing plotting packages'''
import matplotlib.pyplot as plt  #Plotting library
from matplotlib.pyplot import specgram 
import matplotlib.pyplot as plt 
import seaborn as sns 

''' Import Keras & Tenserflow packages'''
#pip install keras
#pip install tensorflow
import keras # to define and train neural network models
from keras import regularizers 
from keras.preprocessing import sequence 
from keras.models import Sequential 
from keras.layers import Dense, Embedding 
from keras.layers import LSTM
from keras.preprocessing.text import Tokenizer 
#from kersas.preprocessing.sequence import pad_sequences 
from keras.utils import to_categorical 
from keras.layers import Input, Flatten, Dropout, Activation
#from keras.layers import conv1D, MaxPoling1D, AveragePooling1D
from keras.models import Model
#from keras.models import ModelCheckpoint
from sklearn.metrics import confusion_matrix

"""**There are two datasets used for this project
RAVDESS: The RAVDESS file contains a unique filename that consists in a 7-part numerical identifier.
TESS: The TESS file contains a unique letter at beginning of file name to identify the emotion. bold text
"""

!pip install Pydrive

"""Authoriziation of google drive to access the data bold text"""

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

import glob

from google.colab import drive

drive.mount('/content/drive',force_remount=True)

!ls "/content/drive/My Drive"

#downloaded = drive.CreateFile({'id':"1lasJX-rkSCxzhcvauvSnMX2RPzQG7Ko4"})   # replace the id with id of file you want to access
#downloaded.GetContentFile('/content/gdrive/My\ Drive/RawData/Ravdess/audio_speech_actors')        # replace the file name with your file
import os
os.path.isfile("content/gdrive/My Drive/RawData/Ravdess/audio_speech_actors")

!pwd

import os
os.chdir("/content/drive/My Drive/RawData/Ravdess/audio_speech_actors") #change the current directory to the location where audio files are saved

currentDir= !pwd
print(currentDir)      #Check the directory we are working in to

#Build list of files
rawdata_list = os.listdir('/content/drive/My Drive/RawData/Ravdess/audio_speech_actors') #Create a list of audio files and assign it to variale rawdata_list

print(rawdata_list)  #print the list

""" ### Librosa and MFCC Configuration
**In order to analyze and standardize how each audio file feature was built, the following configurations were determined:
res_type: resample type (kaiser_best or kaiser_fast)

By default, this uses a high-quality (but relatively slow) method (‘kaiser_best’) for band-limited sinc interpolation. The alternate res_type values listed below offer different trade-offs of speed and quality.
librosa.core.load(path, sr=22050, mono=True, offset=0.0, duration=None, dtype=<class 'numpy.float32'>, res_type='kaiser_best')
I will use this function to extract the audio amplitude at different sampling rates.
path: path to the input file.
sr: target sampling rate. The default
mono: convert signal to mono
offset: start reading after this time (in seconds)
duration: only load up to this much audio (in seconds)
res_type: resample type (kaiser_best or kaiser_fast)
"""

#sample feature
#librosa.core.load(path, sr=22050, mono=True, offset=0.0, duration=None, dtype=<class 'numpy.float32'>, res_type='kaiser_best')
res_type_s = 'kaiser_best'
duration_s = None
sample_rate_s = 22050
offset_s = 0.5

#Mfcc
#librosa.feature.mfcc(y=None, sr=22050, S=None, n_mfcc=20, dct_type=2, norm='ortho', lifter=0, **kwargs)
mfcc_sample_rate = 22050
n_mfcc = 40
axis_mfcc = 1

"""Emotion features in Ravdess **bold text**"""

#Build list with target variables for each file
feeling_list=[]

#Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fear, 07 = disgust, 08 = surprised)  Assign emotions based on filename

for emotion_path in rawdata_list:
  if emotion_path.split('-')[2] == '01':
        feeling_list.append("neutral")
  elif emotion_path.split('-')[2] == '02':
        feeling_list.append("calm")
  elif emotion_path.split('-')[2] == '03':
        feeling_list.append("happy")
  elif emotion_path.split('-')[2] == '04':
        feeling_list.append("sad")
  elif emotion_path.split('-')[2] == '05':
        feeling_list.append("angry")
  elif emotion_path.split('-')[2] == '06':
        feeling_list.append("fear")
  elif emotion_path.split('-')[2] == '07':
        feeling_list.append("disgust")
  elif emotion_path.split('-')[2] == '08':
        feeling_list.append("surprised")
  else:
        feeling_list.append("unknown")

#Check list
feeling_list

#Turn list into dataframe
labels = pd.DataFrame(feeling_list)

#Check shape
labels.shape

#Change index name to "emotion"
labels = labels.rename({0: 'emotion'}, axis=1)

labels.shape

#Count the number of files per emotion
labels_total = pd.DataFrame(labels.groupby(['emotion']).size())
labels_total

!pwd

rawdata_ravdess = pd.DataFrame(columns=['feature'])
bookmark=0

for y in rawdata_list:
    #Change to kaiser_best & 22050 kHz
    #sr > target sampling rate
    #offset=0.5
    X, sample_rate = librosa.load('/content/drive/My Drive/RawData/Ravdess/audio_speech_actors/'+y, 
                                  res_type = res_type_s,
                                  duration = duration_s,
                                  sr = sample_rate_s,
                                  offset = offset_s)
    sample_rate = np.array(sample_rate)
    
    #Get MFCCs from each file
    mfccs = librosa.feature.mfcc(   y=X, 
                                    sr = mfcc_sample_rate, 
                                    n_mfcc = n_mfcc)
    
    #Calculate mean of MFCCs
    mfccs_mean = np.mean(    mfccs, 
                             axis = axis_mfcc)
    feature = mfccs_mean
    
    #Add MFCCs feature results to list
    rawdata_ravdess.loc[bookmark] = [feature]
    bookmark=bookmark+1

#Verify data results
rawdata_ravdess.shape

#Check that there are no null values
rawdata_ravdess.isnull().values.any()

#array sample of features
rawdata_ravdess

#Turn array into dataframe
rawdata_ravdess_final = pd.DataFrame(rawdata_ravdess['feature'].values.tolist())

#Analyze new dataframe shape
rawdata_ravdess_final.shape

# Check data sample
rawdata_ravdess_final.head()

import pandas as pd
#Join labels with features
newdf_ravdess = pd.concat([rawdata_ravdess_final,labels], axis=1)

#Rename dataframe
newdf_ravdess = newdf_ravdess.rename(index=str, columns={"0": "label"})

#Analyze dataframe shape
newdf_ravdess.shape

#Anayze dataframe sample
newdf_ravdess.head()

#Datafram drop NA values
newdf_ravdess.dropna(inplace=True)  # Dropping N/A from the dataset

from sklearn.utils import shuffle

#Shuffle dataframe
newdf_ravdess = shuffle(newdf_ravdess)
newdf_ravdess.head(8)

#Verify that there are no null values
newdf_ravdess.isnull().values.any()

# Check dataframe sample
newdf_ravdess.head(5)

#Analyz shape of dataframe
newdf_ravdess.shape

# see number of emotions
newdf_ravdess[newdf_ravdess.columns[-1]].nunique()

#Move dataframe into separate file
newdf_ravdess.to_csv('emotion_capstone_final_ravdess_dataframe_Anuj_Goyal.csv')

"""**Import and read TESS Dataset**"""

from scipy.io import wavfile
import pandas as pd
import numpy as np
import glob 
import sys
import os
# Build list of audio files

os.chdir('/content/drive/My Drive/RawData/TESS Toronto emotional speech set data')

mypath = !pwd
raw_data_tess_path1=str(mypath)
raw_data_tess_path2 = raw_data_tess_path1.replace("'", "")
raw_data_tess_path3 = raw_data_tess_path2.replace("[", "")
raw_data_tess_path = raw_data_tess_path3.replace("]", "/")




print(raw_data_tess_path)
folder_list_tess = os.listdir('/content/drive/My Drive/RawData/TESS Toronto emotional speech set data/')

#print(folder_list_tess)

tess_list = []

for folder in folder_list_tess:
    folder_path = raw_data_tess_path + folder+'//'
    os.chdir(folder_path)
    for file in glob.glob("*.wav"):
        tess_list.append(folder_path+file)

#Check results
tess_list[:8]
#print(len(tess_list))

#Build list of emotions for Tess
feeling_list_tess = []

#'angry', 'disgust', 'fear', 'happy', 'sad' and 'surprised' emotion classes respectively.  

emotion_dic = {"angry":'angry', 
               "disgust":'disgust', 
               "fear":'fear', 
               "happy":'happy',  
               "sad":'sad', 
               "ps":'surprised',
               "neutral" :'neutral'}

for file_path in tess_list:
    file = file_path.split("\\")[-1] 
    file_name = file.split(".")[0] 
    #print(file_name)
    #x= file_name.rsplit('_')[-1]
    x=file_name.split("_")[-1]
    feeling_list_tess.append(emotion_dic[x])

#Verify emotions
feeling_list_tess

#Build dataframe from array
labels_tess = pd.DataFrame(feeling_list_tess)

#Check results
labels_tess.head()

print(labels_tess)

#Rename column to emotion
labels_tess = labels_tess.rename({0: 'emotion'}, axis=1)

#Check shape
labels_tess.shape

#Check results
labels_tess.head()

#Check emotion size
labels_tess_total = pd.DataFrame(labels_tess.groupby(['emotion']).size())
labels_tess_total

"""**Audio features for TESS**"""

rawdata_tess = pd.DataFrame(columns=['feature'])
bookmark=0

for y in tess_list:
    #Get audio features
    X, sample_rate = librosa.load(y, 
                                  res_type = res_type_s,
                                  duration = duration_s,
                                  sr = sample_rate_s,
                                  offset=offset_s)
    
    #Get MFFC features
    mfccs = librosa.feature.mfcc(   y=X, 
                                    sr = mfcc_sample_rate, 
                                    n_mfcc = n_mfcc)
    #Get MFFCs average features
    mfccs_mean = np.mean(    mfccs, 
                             axis = axis_mfcc)
    feature = mfccs_mean
    rawdata_tess.loc[bookmark] = [feature]
    bookmark=bookmark+1

#Verify Tess features shape
rawdata_tess.shape

#Check that there are no nan values
rawdata_tess.isnull().values.any()

#Get sample data
rawdata_tess.head()

#Build list
rawdata_tess_final = pd.DataFrame(rawdata_tess['feature'].values.tolist())

#Check dataframe
rawdata_tess_final

"""**Combine TESS features and targets**"""

#Concat both feature table and target table 
newdf_tess = pd.concat([rawdata_tess_final,labels_tess], axis=1)
newdf_tess

newdf_tess = newdf_tess.rename(index=str, columns={"0": "label"})

#Verify table shape
newdf_tess.shape

#Get dataframe sample data
newdf_tess.head()

#Drop nan values
newdf_tess.dropna(inplace=True)
newdf_tess.shape

#Shuffle rows
newdf_tess = shuffle(newdf_tess)
newdf_tess.head(10)

#Verify there are no nan values
newdf_tess.isnull().values.any()

#Check shape
newdf_tess.shape

# See number of emotions
newdf_tess[newdf_tess.columns[-1]].nunique()

#Move dataframe into separate file
newdf_tess.to_csv('emotion_capstone_final_tess_dataframe_Anuj_Goyal.csv')

"""** Join RAVDESS + TESS dataframes**"""

newdf_ravdess.columns

newdf_tess.columns

frames = [newdf_ravdess,newdf_tess]

final_dataframe = pd.concat(frames, ignore_index=True)
final_dataframe.shape

#Check new and final dataframe
final_dataframe

#Move dataframe into separate file
final_dataframe.to_csv('emotion_capstone_final_dataframe_Anuj_Goyal.csv')

"""**Divide the data in to train and test set**"""

#Split features from targets
X = final_dataframe.iloc[:,:-1]

#Split targets
y = final_dataframe.iloc[:,-1]

#Get sample of target
y

#Get sample of features
X

from sklearn.model_selection import train_test_split

#Split train & test dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                                    test_size=0.2, 
                                                    random_state=1)

# Check out the data
print(f'X_train shape: {X_train.shape}')
print(f'y_train shape: {y_train.shape}')
print(f'X_test shape: {X_test.shape}')
print(f'y_test shape: {y_test.shape}')

#Check unique values for y_test
y_test.unique()

#Check unique values for y_train
y_train.unique()

#Label Encoding
import keras.utils as kutils
from sklearn.preprocessing import LabelEncoder
import numpy as np
from keras import utils as np_utils

lb = LabelEncoder()

#Encode emotion labels into numbers
y_train_lb = np_utils.to_categorical(lb.fit_transform(y_train))
y_test_lb = np_utils.to_categorical(lb.fit_transform(y_test))


# Check out the data
print(f'X_train shape: {X_train.shape}')
print(f'y_train shape: {y_train_lb.shape}')
print(f'X_test shape: {X_test.shape}')
print(f'y_test shape: {y_test_lb.shape}')

import numpy as np
#Check encoding
np.unique(y_train_lb, axis=0)

# range of x values
print(f'X range: {X_train.min()}-{X_train.max()}')
# y unique values
print(f'y values: {np.unique(y_train_lb)}')
num_classes = len(np.unique(y_train_lb))
print(f'Number of classes: {num_classes}')

"""** Build list of labels for confusion matrix after model**"""

#Check encoding labels
lb.classes_

#Build new lists of encoding labels
y_labels_encoded = {}
for i, label in enumerate(lb.classes_):
    y_labels_encoded[i] = label
    
y_labels_encoded

"""**Scale data for analysis**"""

from sklearn.preprocessing import StandardScaler
#Normalize the data
scaler = StandardScaler()
scaler.fit(X_train)
X_train_scalled = scaler.transform(X_train)
X_test_scalled = scaler.transform(X_test)

"""**Build Model - Random Forest**"""

from sklearn.tree import DecisionTreeClassifier

#fitting the DT
DT_model_one = DecisionTreeClassifier()
DT_model_one.fit(X_train, y_train_lb)

#Getting the score
print(f"The classification accuracy is: {DT_model_one.score(X_train, y_train_lb)}")
print(f"The classification accuracy is: {DT_model_one.score(X_test, y_test_lb)}")

"""As we can see we still havent achieved adequate accuracy in results.
with 64% accuracy, We can say Its is not a  satisfactory model.( Random Forest Model)

**MLP Classifier***
"""

from sklearn.neural_network import MLPClassifier

#Initialize the Multi layer perceptron classifier 
model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)

#Train the model
model.fit(X_train,y_train)

""". Let’s predict the values for the test set. This gives us y_pred (the predicted emotions for the features in the test set)."""

#Predict for the test set
y_pred=model.predict(X_test)

"""**To calculate the accuracy of our model, we’ll call up the accuracy_score() function we imported from sklearn. Finally, we’ll round the accuracy to 2 decimal places and print it out.**"""

from sklearn.metrics import accuracy_score
#Calculate the accuracy of our model
accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)

#DataFlair - Print the accuracy
print("Accuracy: {:.2f}%".format(accuracy*100))

"""** Result from MLP model is much better than Random forest model. 74.47% accuracy is satisfactory result. Now lets try CNN classification model and see if we get better results**

***Lets dive in to CNN model and check results***

**Build model - Convolution Neural Network**

**Change dimensions for CNN model**
"""

#Add dimension for CNN
x_traincnn = np.expand_dims(X_train_scalled, axis=2)
x_testcnn = np.expand_dims(X_test_scalled, axis=2)

#Check shapes of dataframes
print(x_traincnn.shape)
print(x_testcnn.shape)

#Import packages for CNN
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Conv1D 
from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, BatchNormalization, Flatten, MaxPooling2D

#Build sequential CNN
CNN_model = Sequential()

#Build first layer
CNN_model.add(Conv1D(16, 5,padding='same',
                 input_shape=(40, 1), activation='relu'))

#Build second layer
CNN_model.add(Conv1D(32, 5,padding='same',activation='relu'))

#Build third layer
CNN_model.add(Conv1D(64, 5,padding='same',activation='relu'))

#Build forth layer
CNN_model.add(Conv1D(128, 5,padding='same',activation='relu'))

#Add dropout
CNN_model.add(Dropout(0.1))

#Flatten 
CNN_model.add(Flatten())

CNN_model.add(Dense(128, activation ='relu'))
CNN_model.add(Dropout(0.1))
CNN_model.add(Dense(64, activation ='relu'))
CNN_model.add(Dense(8, activation='softmax'))

#Look at CNN model summary
CNN_model.summary()

from keras.utils import plot_model

# Save an image of the model's architecture to a file
plot_model(CNN_model, to_file='Feed Forward NN.png', show_shapes=True, show_layer_names=True)

# Compile the model with the desired loss function, optimizer, and metric to optimize
CNN_model.compile(loss = 'categorical_crossentropy',
                  optimizer = 'Adam',
                  metrics = ['accuracy'])

from keras.callbacks import ModelCheckpoint 

checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_cnn.hdf5', 
                               verbose=1, save_best_only=True)

#Model fit
cnn_results = CNN_model.fit(x_traincnn, y_train_lb,
              batch_size = 64,
              epochs = 25,
              verbose = 1,
              validation_data = (x_testcnn, y_test_lb))

#Plot model accuracy over ephocs
plt.plot(cnn_results.history['accuracy'])
plt.plot(cnn_results.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Calculate pre-training accuracy 
score = CNN_model.evaluate(x_testcnn, y_test_lb, verbose=1)
accuracy = 100*score[1]

print("Pre-training accuracy: %.4f%%" % accuracy)

# Evaluating the model on the training and testing set
score = CNN_model.evaluate(x_traincnn, y_train_lb, verbose=0)
print("Training Accuracy: ", score[1])

score = CNN_model.evaluate(x_testcnn, y_test_lb, verbose=0)
print("Testing Accuracy: ", score[1])

"""** There is a significant increase in the accracy with 85.56% with CNN model**

---

**Add Confusion Matrix**
"""



#Get predictions from model
y_test_predictions = CNN_model.predict_classes(x_testcnn)
y_test_predictions

y_test

#Get labels for emotions
y_labels_encoded

# Change predictions to emotions in order to compare
y_test_predictions_labels =[]

#Go through each prediction and append to new list
for e in range(len(y_test_predictions)):
    y_test_predictions_labels.append(y_labels_encoded[y_test_predictions[e]])
    
#Build array of predictions
y_test_predictions_labels = np.array(y_test_predictions_labels)
y_test_predictions_labels

from sklearn.metrics import confusion_matrix

#Build confusion matrix and see results
confusion_matrix = confusion_matrix(y_test, y_test_predictions_labels)
confusion_matrix

#See confusion matrix shape
confusion_matrix.shape

#Turn al correct answers into 0 to visualize errors better
for i in range(confusion_matrix.shape[0]):
    for j in range(confusion_matrix.shape[1]):
        if i == j:
            confusion_matrix[i,j] = 0

# See results
confusion_matrix

#Add labels to confusion matrix
confusion_matrix = pd.DataFrame(confusion_matrix, columns=list(y_labels_encoded.values()), index=list(y_labels_encoded.values()))

print("The rows represents the true values or observations")
print("The columns respresent the model's predictions")

#Print confusion matrix results
confusion_matrix

#Plot confusion matrix with results
ax = sns.heatmap(confusion_matrix, annot=True)

"""**Save CNN Model**"""

from keras.models import model_from_json
# serialize model to json
json_model = CNN_model.to_json()
#save the model architecture to JSON file
with open('capstone_project_emotion_detection_final_version.json', 'w') as json_file:
    json_file.write(json_model)
#saving the weights of the model
CNN_model.save_weights('capstone_project_emotion_detection_final_version.h5')
#Model loss and accuracy
print("Saved model to disk")

# load json and create model
json_file = open('capstone_project_emotion_detection_final_version.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
# load weights into new model
loaded_model.load_weights("capstone_project_emotion_detection_final_version.h5")
print("Loaded model from disk")

from keras.initializers import glorot_uniform
#Reading the model from JSON file
with open('capstone_project_emotion_detection_final_version.json', 'r') as json_file:
    json_savedModel= json_file.read()
#load the model architecture 
model_load = keras.models.model_from_json(json_savedModel)
model_load.summary()

